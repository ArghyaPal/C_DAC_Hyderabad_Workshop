{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k Nearest Neighbors part 2\n",
    "\n",
    "In the last lab assignment, we used *kNeighborsClassifier()* function of *scikit-learn* to solve the given problem. In this assignment, we would write our own implementation of k Nearest Neighbors. \n",
    "\n",
    "Note: *StackOverFlow* is programmer's best friend. If you have any doubts syntax related or otherwise, there is a high probability that someone would have already posted about it.\n",
    "\n",
    "We will use Breast cancer database provided by UCI Machine Learning repository. \n",
    "\n",
    "* This https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data contains the breast cancer database. \n",
    "\n",
    "* This https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names contains the details of what each attribute represents in the data. \n",
    "\n",
    "* In short, Class <b> 2 </b> reprsents benign tumour and Class <b> 4 </b> represents malignant tumour.\n",
    "\n",
    "## Writing your own k Nearest Neighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import required stuff.\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import pandas as pd \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# k nearest neighbors function.\n",
    "# euclidean distance between datapoints is calculated using np.linalg.norm(np.array(features) - np.array(predict))\n",
    "# this fn. returns vote_result and confidence.\n",
    "def k_nearest_neighbors(data, predict, k=3):\n",
    "\tif len(data) >= k :\n",
    "\t\twarnings.warn(' k is set to a value less than total voting groups! ')\n",
    "\n",
    "\tdistances = []\n",
    "\n",
    "\tfor group in data:\n",
    "\t\tfor features in data[group]:\n",
    "\t\t\teuclidean_distance = np.linalg.norm(np.array(features) - np.array(predict))\n",
    "\t\t\tdistances.append([euclidean_distance, group])\n",
    "\n",
    "\tvotes = [i[1] for i in sorted(distances)[:k]]\n",
    "\tvote_result = Counter(votes).most_common(1)[0][0]\n",
    "\tconfidence = Counter(votes).most_common(1)[0][1] / k \n",
    "\t\n",
    "\n",
    "\treturn vote_result, confidence  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('correct: ', 134)\n",
      "('total: ', 139)\n",
      "('correct: ', 135)\n",
      "('total: ', 139)\n",
      "('correct: ', 135)\n",
      "('total: ', 139)\n",
      "('correct: ', 135)\n",
      "('total: ', 139)\n",
      "('correct: ', 133)\n",
      "('total: ', 139)\n",
      "0.96690647482\n"
     ]
    }
   ],
   "source": [
    "# accuracies list - to print average accuracy of 5 predictions.\n",
    "# We use the same \"Breast cancer dataset of UCI Machine Learning repository.\n",
    "accuracies = []\n",
    "\n",
    "for i in range(5):\n",
    "\tdf = pd.read_csv(\"data/breast-cancer-wisconsin.data.txt\")\n",
    "\tdf.replace('?', -99999, inplace=True)\n",
    "\tdf.drop(['id'], 1, inplace=True)\n",
    "\n",
    "\tfull_data = df.astype(float).values.tolist()\n",
    "\trandom.shuffle(full_data)\n",
    "    # Use random 80-20 split of data into trainset and testset resp.\n",
    "\ttest_size = 0.2\n",
    "\ttrain_set = {2:[], 4:[]}\n",
    "\ttest_set = {2:[], 4:[]}\n",
    "\n",
    "\ttrain_data = full_data[:-int(test_size*len(full_data))]\n",
    "\ttest_data = full_data[-int(test_size*len(full_data)) :]\n",
    "\n",
    "\tfor i in train_data:\n",
    "\t\ttrain_set[i[-1]].append(i[:-1])\n",
    "\n",
    "\tfor i in test_data:\n",
    "\t\ttest_set[i[-1]].append(i[:-1])\n",
    "\n",
    "\tcorrect = 0\n",
    "\ttotal = 0\n",
    "\n",
    "\tfor group in test_set:\n",
    "\t\tfor data in test_set[group]:\n",
    "\t\t\tvote, confidence = k_nearest_neighbors(train_set, data, k=5)\n",
    "\t\t\tif group == vote:\n",
    "\t\t\t\tcorrect = correct+1\n",
    "\t\t\t#else:\n",
    "\t\t\t#\tprint(confidence)\t\t\n",
    "\t\t\ttotal = total+1\n",
    "\n",
    "\tprint('correct: ', correct)\n",
    "\tprint('total: ', total)\t\t\n",
    "\t#print('Accuracy: ', correct/total)\n",
    "\taccuracies.append(correct/ float(total))\n",
    "# Printing average accuracy\n",
    "print(sum(accuracies)/float(len(accuracies)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions:\n",
    "\n",
    "  1. Compare the accuracy and confidence values obtained between using inbuilt *scikit-learn* function and our own custom implementation. Do you observe any difference ? If so, please explain the observation.\n",
    "  2. Compare the running time of using the in-built *scikit-learn* function and your own custom function. Which is faster? Why do you think so? What are the ways in which the slower one can be made faster?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
